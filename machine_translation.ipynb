{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b490ec6b",
   "metadata": {
    "id": "JCTPsmJEGUyx",
    "papermill": {
     "duration": 0.025699,
     "end_time": "2021-08-16T08:59:34.165464",
     "exception": false,
     "start_time": "2021-08-16T08:59:34.139765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901977cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T08:59:34.229713Z",
     "iopub.status.busy": "2021-08-16T08:59:34.229164Z",
     "iopub.status.idle": "2021-08-16T08:59:38.379432Z",
     "shell.execute_reply": "2021-08-16T08:59:38.378801Z",
     "shell.execute_reply.started": "2021-08-16T08:47:38.474974Z"
    },
    "id": "TSbr_dtvZNvY",
    "papermill": {
     "duration": 4.188699,
     "end_time": "2021-08-16T08:59:38.379578",
     "exception": false,
     "start_time": "2021-08-16T08:59:34.190879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import spacy.cli\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import  nltk.translate.bleu_score as bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "smoothie = SmoothingFunction().method4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9115f6cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T08:59:38.435791Z",
     "iopub.status.busy": "2021-08-16T08:59:38.434919Z",
     "iopub.status.idle": "2021-08-16T08:59:54.919179Z",
     "shell.execute_reply": "2021-08-16T08:59:54.919758Z",
     "shell.execute_reply.started": "2021-08-16T08:47:42.270536Z"
    },
    "id": "fp2_zAtzTq3Y",
    "outputId": "947b9e8d-1f3a-4921-d6d7-9490e83aa389",
    "papermill": {
     "duration": 16.514686,
     "end_time": "2021-08-16T08:59:54.919954",
     "exception": false,
     "start_time": "2021-08-16T08:59:38.405268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab9ded2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T08:59:54.975286Z",
     "iopub.status.busy": "2021-08-16T08:59:54.974748Z",
     "iopub.status.idle": "2021-08-16T08:59:59.955763Z",
     "shell.execute_reply": "2021-08-16T08:59:59.956343Z",
     "shell.execute_reply.started": "2021-08-16T08:48:04.663993Z"
    },
    "id": "SACbO5SxUIwV",
    "papermill": {
     "duration": 5.010337,
     "end_time": "2021-08-16T08:59:59.956508",
     "exception": false,
     "start_time": "2021-08-16T08:59:54.946171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4083c8a5",
   "metadata": {
    "id": "saH6sbIzGW7V",
    "papermill": {
     "duration": 0.028284,
     "end_time": "2021-08-16T09:00:00.031876",
     "exception": false,
     "start_time": "2021-08-16T09:00:00.003592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61255ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:00.094705Z",
     "iopub.status.busy": "2021-08-16T09:00:00.093735Z",
     "iopub.status.idle": "2021-08-16T09:00:00.096083Z",
     "shell.execute_reply": "2021-08-16T09:00:00.096491Z",
     "shell.execute_reply.started": "2021-08-16T08:48:13.378694Z"
    },
    "id": "WksChklP9BGC",
    "papermill": {
     "duration": 0.036394,
     "end_time": "2021-08-16T09:00:00.096662",
     "exception": false,
     "start_time": "2021-08-16T09:00:00.060268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = '../input/machinetranslation/Hindi_English_Truncated_Corpus (1).csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d352b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:00.158589Z",
     "iopub.status.busy": "2021-08-16T09:00:00.158035Z",
     "iopub.status.idle": "2021-08-16T09:00:01.425845Z",
     "shell.execute_reply": "2021-08-16T09:00:01.425368Z",
     "shell.execute_reply.started": "2021-08-16T08:48:33.185635Z"
    },
    "id": "x4YsAwU6-XG3",
    "outputId": "d48c6faf-ccd7-44c9-e711-10947438deda",
    "papermill": {
     "duration": 1.300371,
     "end_time": "2021-08-16T09:00:01.425974",
     "exception": false,
     "start_time": "2021-08-16T09:00:00.125603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(root_dir, encoding='utf-8')\n",
    "df = df.dropna()\n",
    "df = df[df['source']=='ted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc72db97",
   "metadata": {
    "id": "WtFKC0PnGRwK",
    "papermill": {
     "duration": 0.024567,
     "end_time": "2021-08-16T09:00:01.477703",
     "exception": false,
     "start_time": "2021-08-16T09:00:01.453136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69014a50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:01.540382Z",
     "iopub.status.busy": "2021-08-16T09:00:01.539705Z",
     "iopub.status.idle": "2021-08-16T09:00:01.542517Z",
     "shell.execute_reply": "2021-08-16T09:00:01.542900Z",
     "shell.execute_reply.started": "2021-08-16T08:48:59.237041Z"
    },
    "id": "u72oKWHqAMa_",
    "papermill": {
     "duration": 0.040376,
     "end_time": "2021-08-16T09:00:01.543030",
     "exception": false,
     "start_time": "2021-08-16T09:00:01.502654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vocabulary():\n",
    "  def __init__(self, threshold=2):\n",
    "    self.threshold = threshold\n",
    "    self.freqs = {}\n",
    "    self.itos = {0: \"<unk>\", 1: \"<pad>\", 2: \"<sos>\", 3: \"<eos>\"}\n",
    "    self.stoi = {\"<unk>\": 0, \"<pad>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
    "  \n",
    "  def build_vocabulary(self, df, en):\n",
    "    idx = 4\n",
    "    if en:\n",
    "      for i in range(len(df)):\n",
    "        eng_text = df.iloc[i, 1]\n",
    "        tokens = [tok.text.lower() for tok in spacy_eng.tokenizer(eng_text)]\n",
    "        for token in tokens:\n",
    "          if token not in self.freqs:\n",
    "            self.freqs[token] = 1\n",
    "          else:\n",
    "            self.freqs[token] += 1\n",
    "          if self.freqs[token] == self.threshold:\n",
    "            self.stoi[token] = idx\n",
    "            self.itos[idx] = token\n",
    "            idx += 1\n",
    "    else:\n",
    "      for i in range(len(df)):\n",
    "        hindi_text = df.iloc[i, 2]\n",
    "        hindi_text = re.sub('r[?,:.]।', '', hindi_text)\n",
    "        for token in hindi_text.split(' '):\n",
    "          if token not in self.freqs:\n",
    "            self.freqs[token] = 1\n",
    "          else:\n",
    "            self.freqs[token] += 1\n",
    "          if self.freqs[token] == self.threshold:\n",
    "            self.stoi[token] = idx\n",
    "            self.itos[idx] = token\n",
    "            idx += 1\n",
    "\n",
    "  def numericalize(self, text, en):\n",
    "    if en:\n",
    "      tokens = [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "    else:\n",
    "      tokens = [token for token in text.lower().split(' ')]\n",
    "    \n",
    "    token_to_indices = [self.stoi[token] if token in self.stoi else self.stoi['<unk>'] for token in tokens]\n",
    "    token_to_indices = [self.stoi['<sos>']] + token_to_indices + [self.stoi['<eos>']]\n",
    "    return token_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6519a8c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:01.634168Z",
     "iopub.status.busy": "2021-08-16T09:00:01.624045Z",
     "iopub.status.idle": "2021-08-16T09:00:07.478341Z",
     "shell.execute_reply": "2021-08-16T09:00:07.477369Z",
     "shell.execute_reply.started": "2021-08-16T08:48:59.658777Z"
    },
    "id": "6gzOuqywRUyA",
    "papermill": {
     "duration": 5.910777,
     "end_time": "2021-08-16T09:00:07.478485",
     "exception": false,
     "start_time": "2021-08-16T09:00:01.567708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_vocab = Vocabulary()\n",
    "hi_vocab = Vocabulary()\n",
    "\n",
    "en_vocab.build_vocabulary(df, en=True)\n",
    "hi_vocab.build_vocabulary(df, en=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9018d6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:07.535968Z",
     "iopub.status.busy": "2021-08-16T09:00:07.535188Z",
     "iopub.status.idle": "2021-08-16T09:00:07.538538Z",
     "shell.execute_reply": "2021-08-16T09:00:07.539178Z",
     "shell.execute_reply.started": "2021-08-16T08:49:09.032775Z"
    },
    "id": "___5FN-YNDqu",
    "outputId": "c5c50b2b-b221-4069-c37e-2caa3f7d8f6b",
    "papermill": {
     "duration": 0.034614,
     "end_time": "2021-08-16T09:00:07.539359",
     "exception": false,
     "start_time": "2021-08-16T09:00:07.504745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 9133\n",
      "Hindi vocab size: 11833\n"
     ]
    }
   ],
   "source": [
    "input_vocab_size = len(en_vocab.stoi)\n",
    "output_vocab_size = len(hi_vocab.stoi)\n",
    "print(f'English vocab size: {input_vocab_size}')\n",
    "print(f'Hindi vocab size: {output_vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef160a37",
   "metadata": {
    "id": "rK4Ku-KuR9Qp",
    "papermill": {
     "duration": 0.025823,
     "end_time": "2021-08-16T09:00:07.591746",
     "exception": false,
     "start_time": "2021-08-16T09:00:07.565923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd4b87c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:07.651008Z",
     "iopub.status.busy": "2021-08-16T09:00:07.649405Z",
     "iopub.status.idle": "2021-08-16T09:00:07.651880Z",
     "shell.execute_reply": "2021-08-16T09:00:07.652275Z",
     "shell.execute_reply.started": "2021-08-16T08:49:10.940269Z"
    },
    "id": "UJNnh7RrRzV-",
    "papermill": {
     "duration": 0.034735,
     "end_time": "2021-08-16T09:00:07.652394",
     "exception": false,
     "start_time": "2021-08-16T09:00:07.617659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MTDataset(Dataset):\n",
    "  def __init__(self, df, en_vocab, hi_voab):\n",
    "    self.df = df\n",
    "    self.en_vocab = en_vocab\n",
    "    self.hi_vocab = hi_vocab\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(df)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "\n",
    "    en_text = df.iloc[index, 1]\n",
    "    hi_text = df.iloc[index, 2]\n",
    "\n",
    "    en_numericalized = en_vocab.numericalize(en_text, en=True)\n",
    "    hi_numericalized = hi_vocab.numericalize(hi_text, en=False)\n",
    "\n",
    "    return torch.tensor(en_numericalized), torch.tensor(hi_numericalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad6a9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:07.708684Z",
     "iopub.status.busy": "2021-08-16T09:00:07.708170Z",
     "iopub.status.idle": "2021-08-16T09:00:07.712296Z",
     "shell.execute_reply": "2021-08-16T09:00:07.711854Z",
     "shell.execute_reply.started": "2021-08-16T08:49:12.315669Z"
    },
    "id": "lh6SrxuVVr6l",
    "papermill": {
     "duration": 0.034442,
     "end_time": "2021-08-16T09:00:07.712393",
     "exception": false,
     "start_time": "2021-08-16T09:00:07.677951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Collate():\n",
    "  def __init__(self, pad_idx):\n",
    "    self.pad_idx = pad_idx\n",
    "  \n",
    "  def __call__(self, batch):\n",
    "    (en, hi) = zip(*batch)\n",
    "    \n",
    "    en_pad = pad_sequence(en, batch_first=False, padding_value=self.pad_idx)\n",
    "    hi_pad = pad_sequence(hi, batch_first=False, padding_value=self.pad_idx)\n",
    "\n",
    "    return en_pad, hi_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3114ef1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:07.770572Z",
     "iopub.status.busy": "2021-08-16T09:00:07.769214Z",
     "iopub.status.idle": "2021-08-16T09:00:07.771833Z",
     "shell.execute_reply": "2021-08-16T09:00:07.772258Z",
     "shell.execute_reply.started": "2021-08-16T08:49:12.659240Z"
    },
    "id": "KgVvH_AWUEHa",
    "papermill": {
     "duration": 0.034489,
     "end_time": "2021-08-16T09:00:07.772378",
     "exception": false,
     "start_time": "2021-08-16T09:00:07.737889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_loader(df, en_vocab, hi_vocab, batch_size=32, num_workers=2, shuffle=True, pin_memory=True):\n",
    "  dataset = MTDataset(df, en_vocab, hi_vocab)\n",
    "  train_size = int(0.8 * len(dataset))\n",
    "  test_size = len(dataset) - train_size\n",
    "  train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "  pad_idx = en_vocab.stoi[\"<pad>\"]\n",
    "  train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle, pin_memory=pin_memory, collate_fn=Collate(pad_idx))\n",
    "  test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, collate_fn=Collate(pad_idx))\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5999563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:07.829067Z",
     "iopub.status.busy": "2021-08-16T09:00:07.828455Z",
     "iopub.status.idle": "2021-08-16T09:00:07.850577Z",
     "shell.execute_reply": "2021-08-16T09:00:07.850062Z",
     "shell.execute_reply.started": "2021-08-16T08:49:14.365911Z"
    },
    "id": "PnDMv8XcURdZ",
    "papermill": {
     "duration": 0.05282,
     "end_time": "2021-08-16T09:00:07.850709",
     "exception": false,
     "start_time": "2021-08-16T09:00:07.797889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loader(df, en_vocab, hi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61c8e0ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:07.904968Z",
     "iopub.status.busy": "2021-08-16T09:00:07.904165Z",
     "iopub.status.idle": "2021-08-16T09:00:07.909587Z",
     "shell.execute_reply": "2021-08-16T09:00:07.908961Z",
     "shell.execute_reply.started": "2021-08-16T08:49:15.536883Z"
    },
    "id": "3FN9aemXUcCQ",
    "outputId": "609fb99c-6d28-4950-fa12-32ad4008a34b",
    "papermill": {
     "duration": 0.033803,
     "end_time": "2021-08-16T09:00:07.909746",
     "exception": false,
     "start_time": "2021-08-16T09:00:07.875943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae57055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:08.009830Z",
     "iopub.status.busy": "2021-08-16T09:00:08.009004Z",
     "iopub.status.idle": "2021-08-16T09:00:12.810542Z",
     "shell.execute_reply": "2021-08-16T09:00:12.809515Z",
     "shell.execute_reply.started": "2021-08-16T08:49:39.414601Z"
    },
    "id": "EZr2Rz3-NMji",
    "papermill": {
     "duration": 4.874946,
     "end_time": "2021-08-16T09:00:12.810717",
     "exception": false,
     "start_time": "2021-08-16T09:00:07.935771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, (en, hi) in enumerate(train_loader):\n",
    "  # shape of en: (eng_source_len, batch_size)\n",
    "  # shape of hi: (hindi_source_len, batch_size)\n",
    "  break\n",
    "for idx, (en, hi) in enumerate(test_loader):\n",
    "  # shape of en: (eng_source_len, batch_size)\n",
    "  # shape of hi: (hindi_source_len, batch_size)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0847dcc",
   "metadata": {
    "id": "QzNW8OR_QKj0",
    "papermill": {
     "duration": 0.026863,
     "end_time": "2021-08-16T09:00:12.864150",
     "exception": false,
     "start_time": "2021-08-16T09:00:12.837287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc5f5dee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:12.921001Z",
     "iopub.status.busy": "2021-08-16T09:00:12.920451Z",
     "iopub.status.idle": "2021-08-16T09:00:12.924492Z",
     "shell.execute_reply": "2021-08-16T09:00:12.924049Z",
     "shell.execute_reply.started": "2021-08-16T08:49:46.399568Z"
    },
    "id": "6CBuNyv-QKEP",
    "papermill": {
     "duration": 0.03434,
     "end_time": "2021-08-16T09:00:12.924613",
     "exception": false,
     "start_time": "2021-08-16T09:00:12.890273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trace(x, name, arg='shape'):\n",
    "  if arg == 'shape':\n",
    "    print(f'Shape of {name}: {x.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3c89f",
   "metadata": {
    "id": "jf8305NrNqOG",
    "papermill": {
     "duration": 0.025437,
     "end_time": "2021-08-16T09:00:12.975621",
     "exception": false,
     "start_time": "2021-08-16T09:00:12.950184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building Encoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e0b3e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:13.035296Z",
     "iopub.status.busy": "2021-08-16T09:00:13.034673Z",
     "iopub.status.idle": "2021-08-16T09:00:13.037862Z",
     "shell.execute_reply": "2021-08-16T09:00:13.037444Z",
     "shell.execute_reply.started": "2021-08-16T08:49:49.840223Z"
    },
    "id": "ExPHUAMkNihE",
    "papermill": {
     "duration": 0.036704,
     "end_time": "2021-08-16T09:00:13.037968",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.001264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_size, embed_size, hidden_size, num_layers, drop_prob):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.embed_size = embed_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = nn.Embedding(input_size, embed_size)\n",
    "    self.rnn = nn.LSTM(embed_size, hidden_size, num_layers, bidirectional=True)\n",
    "    \n",
    "    self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "    self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "    self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # shape of x: (seq_length, batch_size)\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "    # shape of embedding: (seq_length, batch_size, embed_size)\n",
    "\n",
    "    encoder_states, (hidden , cell) = self.rnn(embedding)\n",
    "  \n",
    "    # shape of encoder_states: (seq_length, batch_size, hidden_size*2)\n",
    "    # shape of hidden: (2*num_layers, batch_size, hidden_size)\n",
    "    # shape of cell: (2*num_layers, batch_size, hidden_size)\n",
    "\n",
    "    hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "    cell = self.fc_hidden(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "    # shape of hidden, cell: (num_layers, batch_size, hidden_size)\n",
    "\n",
    "    return encoder_states, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20b496cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:13.098990Z",
     "iopub.status.busy": "2021-08-16T09:00:13.098435Z",
     "iopub.status.idle": "2021-08-16T09:00:13.266708Z",
     "shell.execute_reply": "2021-08-16T09:00:13.267261Z",
     "shell.execute_reply.started": "2021-08-16T08:49:50.238619Z"
    },
    "id": "dBewKnjPPac8",
    "outputId": "9111ab15-a44e-46f4-8496-6a1f40cdcf8b",
    "papermill": {
     "duration": 0.203918,
     "end_time": "2021-08-16T09:00:13.267456",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.063538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 32, 512])\n",
      "torch.Size([1, 32, 256])\n",
      "torch.Size([1, 32, 256])\n"
     ]
    }
   ],
   "source": [
    "# Testing encoder\n",
    "X = torch.zeros((35, 32)).long()\n",
    "encoder = Encoder(input_vocab_size, 300, 256, 1, drop_prob=0.5)\n",
    "encoder_states, hidden, cell = encoder(X)\n",
    "print(encoder_states.shape)\n",
    "print(hidden.shape)\n",
    "print(cell.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0bb9e6",
   "metadata": {
    "id": "Hw4sZKc0RJVy",
    "papermill": {
     "duration": 0.025646,
     "end_time": "2021-08-16T09:00:13.319922",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.294276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f23a15e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:13.383775Z",
     "iopub.status.busy": "2021-08-16T09:00:13.382418Z",
     "iopub.status.idle": "2021-08-16T09:00:13.384845Z",
     "shell.execute_reply": "2021-08-16T09:00:13.385259Z",
     "shell.execute_reply.started": "2021-08-16T08:49:52.596970Z"
    },
    "id": "7MyJSndvP0rV",
    "papermill": {
     "duration": 0.039801,
     "end_time": "2021-08-16T09:00:13.385395",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.345594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, input_size, embed_size, hidden_size, output_size, num_layers, drop_prob):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.embed_size = embed_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = nn.Embedding(input_size, embed_size)\n",
    "    self.rnn = nn.LSTM(hidden_size * 2 + embed_size, hidden_size, num_layers)\n",
    "\n",
    "    self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "    self.dropout = nn.Dropout(drop_prob)\n",
    "    self.softmax = nn.Softmax(dim=0)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x, encoder_states, hidden, cell):\n",
    "    # shape of x: (batch_size)\n",
    "    x = x.unsqueeze(0) # (1, batch_size)\n",
    "\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "    # shape of embedding: (1, batch_size, embed_size)\n",
    "\n",
    "    seq_len = encoder_states.shape[0]\n",
    "    \n",
    "    h_reshaped = hidden.repeat(seq_len, 1, 1)\n",
    "    # shape of h_reshaped: (seq_len, batch_size, hidden_size*2)\n",
    "    \n",
    "    energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "    # shape of energy: (seq_len, batch_size, 1)\n",
    "\n",
    "    attention = self.softmax(energy)\n",
    "    # shape of attention: (seq_len, batch_size, 1)\n",
    "\n",
    "    attention = attention.permute(1,2,0)\n",
    "    # shape of attention: (batch_size, 1, seq_len)\n",
    "\n",
    "    encoder_states = encoder_states.permute(1,0,2)\n",
    "    # shape of encoder_states: (batch_size, seq_len, hidden_size*2)\n",
    "\n",
    "    context_vector = torch.bmm(attention, encoder_states)\n",
    "    # shape of context_vector: (batch_size, 1, hidden_size * 2)\n",
    "\n",
    "    # we want (1, batch_size, hidden_size * 2)\n",
    "    context_vector = context_vector.permute(1,0,2)\n",
    "\n",
    "    rnn_input = torch.cat([context_vector, embedding], dim=2)\n",
    "\n",
    "    outputs, (hidden, cell) = self.rnn(rnn_input, (hidden,cell))\n",
    "    # shape of outputs: (1, batch_size, hidden_size)\n",
    "\n",
    "    predictions = self.fc(outputs)\n",
    "    # shape of predictions: (1, batch_size, target_vocabulary_size)\n",
    "\n",
    "    predictions = predictions.squeeze(0)\n",
    "    # shape of predictions: (batch_size, target_vocabulary_size), since loss calculation needs this dimension\n",
    "\n",
    "    return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09708e",
   "metadata": {
    "id": "VhDQlu5GXwcM",
    "papermill": {
     "duration": 0.025484,
     "end_time": "2021-08-16T09:00:13.436939",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.411455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seq2Seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c10faac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:13.495985Z",
     "iopub.status.busy": "2021-08-16T09:00:13.495306Z",
     "iopub.status.idle": "2021-08-16T09:00:13.499116Z",
     "shell.execute_reply": "2021-08-16T09:00:13.498687Z",
     "shell.execute_reply.started": "2021-08-16T08:49:53.421965Z"
    },
    "id": "I5iOt6XuXs3U",
    "papermill": {
     "duration": 0.036719,
     "end_time": "2021-08-16T09:00:13.499221",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.462502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "  def __init__(self, encoder, decoder, output_vocab_size):\n",
    "    super(Seq2Seq, self).__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.output_vocab_size = output_vocab_size\n",
    "  \n",
    "  def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "    # shape of source: (num_steps_in_source, batch_size)\n",
    "    # shape of target: (num_steps_in_target, batch_size)\n",
    "    batch_size = source.shape[1]\n",
    "    target_len = target.shape[0]\n",
    "    target_vocab_size = self.output_vocab_size\n",
    "\n",
    "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "    encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "    # First input is <sos> token\n",
    "    x = target[0]\n",
    "\n",
    "    for t in range(1, target_len):\n",
    "      output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "      # store predictions for current timestep\n",
    "      outputs[t] = output\n",
    "\n",
    "      # get the best word the decoder predicted \n",
    "      best_guess = output.argmax(1)\n",
    "\n",
    "      x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0c942ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:13.554262Z",
     "iopub.status.busy": "2021-08-16T09:00:13.553506Z",
     "iopub.status.idle": "2021-08-16T09:00:13.556346Z",
     "shell.execute_reply": "2021-08-16T09:00:13.555886Z",
     "shell.execute_reply.started": "2021-08-16T08:49:53.869545Z"
    },
    "id": "pnTG6WpgZVxK",
    "papermill": {
     "duration": 0.031651,
     "end_time": "2021-08-16T09:00:13.556451",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.524800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Device config\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc23f58",
   "metadata": {
    "id": "YJy1jyozZrOr",
    "papermill": {
     "duration": 0.025557,
     "end_time": "2021-08-16T09:00:13.607513",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.581956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21096c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:13.663459Z",
     "iopub.status.busy": "2021-08-16T09:00:13.662547Z",
     "iopub.status.idle": "2021-08-16T09:00:13.665540Z",
     "shell.execute_reply": "2021-08-16T09:00:13.665101Z",
     "shell.execute_reply.started": "2021-08-16T08:50:02.213255Z"
    },
    "id": "9-A-NLylZf0i",
    "papermill": {
     "duration": 0.032313,
     "end_time": "2021-08-16T09:00:13.665677",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.633364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2ced59f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:13.726052Z",
     "iopub.status.busy": "2021-08-16T09:00:13.725172Z",
     "iopub.status.idle": "2021-08-16T09:00:13.728126Z",
     "shell.execute_reply": "2021-08-16T09:00:13.727557Z",
     "shell.execute_reply.started": "2021-08-16T08:50:02.651020Z"
    },
    "id": "PB-eKplAZqc4",
    "papermill": {
     "duration": 0.034941,
     "end_time": "2021-08-16T09:00:13.728240",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.693299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "input_size_encoder = len(en_vocab.stoi)\n",
    "input_size_decoder = len(hi_vocab.stoi)\n",
    "output_size = len(hi_vocab.stoi)\n",
    "encoder_embed_size = 300\n",
    "decoder_embed_size = 300\n",
    "hidden_size = 1024 # according to paper\n",
    "num_layers = 1\n",
    "enc_dropout = 0.2\n",
    "dec_dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14d4744c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:13.787458Z",
     "iopub.status.busy": "2021-08-16T09:00:13.786782Z",
     "iopub.status.idle": "2021-08-16T09:00:14.864167Z",
     "shell.execute_reply": "2021-08-16T09:00:14.866692Z",
     "shell.execute_reply.started": "2021-08-16T08:50:03.725566Z"
    },
    "id": "gHkJvb_6aJLU",
    "papermill": {
     "duration": 1.110996,
     "end_time": "2021-08-16T09:00:14.866935",
     "exception": false,
     "start_time": "2021-08-16T09:00:13.755939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(input_size_encoder, encoder_embed_size, hidden_size, num_layers, enc_dropout).to(device)\n",
    "decoder = Decoder(input_size_decoder, decoder_embed_size, hidden_size, output_size, num_layers, enc_dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fca9b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:14.991625Z",
     "iopub.status.busy": "2021-08-16T09:00:14.990586Z",
     "iopub.status.idle": "2021-08-16T09:00:14.995085Z",
     "shell.execute_reply": "2021-08-16T09:00:14.995705Z",
     "shell.execute_reply.started": "2021-08-16T08:50:05.436223Z"
    },
    "id": "-05Cqsljawwf",
    "papermill": {
     "duration": 0.067055,
     "end_time": "2021-08-16T09:00:14.995905",
     "exception": false,
     "start_time": "2021-08-16T09:00:14.928850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder, decoder, output_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = en_vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59f49e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T09:00:15.099422Z",
     "iopub.status.busy": "2021-08-16T09:00:15.098311Z",
     "iopub.status.idle": "2021-08-16T11:39:22.241205Z",
     "shell.execute_reply": "2021-08-16T11:39:22.241612Z",
     "shell.execute_reply.started": "2021-08-16T08:50:05.459235Z"
    },
    "id": "ig9IAAjCbLNG",
    "outputId": "f04aeb50-2e90-427e-fcbf-0d78017faef5",
    "papermill": {
     "duration": 9547.202907,
     "end_time": "2021-08-16T11:39:22.241804",
     "exception": false,
     "start_time": "2021-08-16T09:00:15.038897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1 / 100]\tLoss: 5.968087\n",
      "Epoch: [2 / 100]\tLoss: 5.315952\n",
      "Epoch: [3 / 100]\tLoss: 4.922323\n",
      "Epoch: [4 / 100]\tLoss: 4.547365\n",
      "Epoch: [5 / 100]\tLoss: 4.178050\n",
      "Epoch: [6 / 100]\tLoss: 3.797237\n",
      "Epoch: [7 / 100]\tLoss: 3.444187\n",
      "Epoch: [8 / 100]\tLoss: 3.110986\n",
      "Epoch: [9 / 100]\tLoss: 2.838454\n",
      "Epoch: [10 / 100]\tLoss: 2.584971\n",
      "Epoch: [11 / 100]\tLoss: 2.354106\n",
      "Epoch: [12 / 100]\tLoss: 2.156367\n",
      "Epoch: [13 / 100]\tLoss: 1.983069\n",
      "Epoch: [14 / 100]\tLoss: 1.822267\n",
      "Epoch: [15 / 100]\tLoss: 1.679757\n",
      "Epoch: [16 / 100]\tLoss: 1.545281\n",
      "Epoch: [17 / 100]\tLoss: 1.423732\n",
      "Epoch: [18 / 100]\tLoss: 1.309048\n",
      "Epoch: [19 / 100]\tLoss: 1.213320\n",
      "Epoch: [20 / 100]\tLoss: 1.120853\n",
      "Epoch: [21 / 100]\tLoss: 1.046750\n",
      "Epoch: [22 / 100]\tLoss: 0.972273\n",
      "Epoch: [23 / 100]\tLoss: 0.902486\n",
      "Epoch: [24 / 100]\tLoss: 0.854790\n",
      "Epoch: [25 / 100]\tLoss: 0.806959\n",
      "Epoch: [26 / 100]\tLoss: 0.759103\n",
      "Epoch: [27 / 100]\tLoss: 0.724405\n",
      "Epoch: [28 / 100]\tLoss: 0.684470\n",
      "Epoch: [29 / 100]\tLoss: 0.653845\n",
      "Epoch: [30 / 100]\tLoss: 0.619847\n",
      "Epoch: [31 / 100]\tLoss: 0.592300\n",
      "Epoch: [32 / 100]\tLoss: 0.564311\n",
      "Epoch: [33 / 100]\tLoss: 0.540087\n",
      "Epoch: [34 / 100]\tLoss: 0.530882\n",
      "Epoch: [35 / 100]\tLoss: 0.522219\n",
      "Epoch: [36 / 100]\tLoss: 0.503051\n",
      "Epoch: [37 / 100]\tLoss: 0.483814\n",
      "Epoch: [38 / 100]\tLoss: 0.472830\n",
      "Epoch: [39 / 100]\tLoss: 0.454336\n",
      "Epoch: [40 / 100]\tLoss: 0.452131\n",
      "Epoch: [41 / 100]\tLoss: 0.442664\n",
      "Epoch: [42 / 100]\tLoss: 0.440068\n",
      "Epoch: [43 / 100]\tLoss: 0.435336\n",
      "Epoch: [44 / 100]\tLoss: 0.425794\n",
      "Epoch: [45 / 100]\tLoss: 0.409294\n",
      "Epoch: [46 / 100]\tLoss: 0.403754\n",
      "Epoch: [47 / 100]\tLoss: 0.405138\n",
      "Epoch: [48 / 100]\tLoss: 0.402576\n",
      "Epoch: [49 / 100]\tLoss: 0.395690\n",
      "Epoch: [50 / 100]\tLoss: 0.396053\n",
      "Epoch: [51 / 100]\tLoss: 0.391421\n",
      "Epoch: [52 / 100]\tLoss: 0.388468\n",
      "Epoch: [53 / 100]\tLoss: 0.376142\n",
      "Epoch: [54 / 100]\tLoss: 0.367819\n",
      "Epoch: [55 / 100]\tLoss: 0.376836\n",
      "Epoch: [56 / 100]\tLoss: 0.371467\n",
      "Epoch: [57 / 100]\tLoss: 0.372955\n",
      "Epoch: [58 / 100]\tLoss: 0.367928\n",
      "Epoch: [59 / 100]\tLoss: 0.363555\n",
      "Epoch: [60 / 100]\tLoss: 0.361811\n",
      "Epoch: [61 / 100]\tLoss: 0.364209\n",
      "Epoch: [62 / 100]\tLoss: 0.369125\n",
      "Epoch: [63 / 100]\tLoss: 0.357130\n",
      "Epoch: [64 / 100]\tLoss: 0.349498\n",
      "Epoch: [65 / 100]\tLoss: 0.352602\n",
      "Epoch: [66 / 100]\tLoss: 0.359838\n",
      "Epoch: [67 / 100]\tLoss: 0.360645\n",
      "Epoch: [68 / 100]\tLoss: 0.357960\n",
      "Epoch: [69 / 100]\tLoss: 0.347562\n",
      "Epoch: [70 / 100]\tLoss: 0.352851\n",
      "Epoch: [71 / 100]\tLoss: 0.355691\n",
      "Epoch: [72 / 100]\tLoss: 0.352957\n",
      "Epoch: [73 / 100]\tLoss: 0.343394\n",
      "Epoch: [74 / 100]\tLoss: 0.346651\n",
      "Epoch: [75 / 100]\tLoss: 0.345325\n",
      "Epoch: [76 / 100]\tLoss: 0.343198\n",
      "Epoch: [77 / 100]\tLoss: 0.346943\n",
      "Epoch: [78 / 100]\tLoss: 0.340876\n",
      "Epoch: [79 / 100]\tLoss: 0.340776\n",
      "Epoch: [80 / 100]\tLoss: 0.338539\n",
      "Epoch: [81 / 100]\tLoss: 0.344106\n",
      "Epoch: [82 / 100]\tLoss: 0.338140\n",
      "Epoch: [83 / 100]\tLoss: 0.340104\n",
      "Epoch: [84 / 100]\tLoss: 0.345796\n",
      "Epoch: [85 / 100]\tLoss: 0.342538\n",
      "Epoch: [86 / 100]\tLoss: 0.335292\n",
      "Epoch: [87 / 100]\tLoss: 0.341704\n",
      "Epoch: [88 / 100]\tLoss: 0.341477\n",
      "Epoch: [89 / 100]\tLoss: 0.346087\n",
      "Epoch: [90 / 100]\tLoss: 0.344339\n",
      "Epoch: [91 / 100]\tLoss: 0.349996\n",
      "Epoch: [92 / 100]\tLoss: 0.342998\n",
      "Epoch: [93 / 100]\tLoss: 0.343706\n",
      "Epoch: [94 / 100]\tLoss: 0.345209\n",
      "Epoch: [95 / 100]\tLoss: 0.351099\n",
      "Epoch: [96 / 100]\tLoss: 0.341587\n",
      "Epoch: [97 / 100]\tLoss: 0.349743\n",
      "Epoch: [98 / 100]\tLoss: 0.341887\n",
      "Epoch: [99 / 100]\tLoss: 0.347622\n",
      "Epoch: [100 / 100]\tLoss: 0.345620\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(num_epochs):\n",
    "  running_loss = 0.0\n",
    "  for batch_idx, (en, hi) in enumerate(train_loader):\n",
    "    input = en.to(device)    # shape: (source_len, batch_size)\n",
    "    target = hi.to(device)    # shape: (target_len, batch_size)\n",
    "    \n",
    "    output = model(input, target)\n",
    "    # output shape: (target_len, batch_size, hindi_vocab_size)\n",
    "\n",
    "    output = output[1:].reshape(-1, output.shape[-1])   # start from 1st index because at 0th index we have start token\n",
    "    target = target[1:].reshape(-1)\n",
    "\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.detach().cpu().item()\n",
    "\n",
    "  print(f'Epoch: [{epoch+1} / {num_epochs}]\\tLoss: {running_loss/len(train_loader):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ba6b1",
   "metadata": {
    "id": "oWThhXbyfUrd",
    "papermill": {
     "duration": 0.050359,
     "end_time": "2021-08-16T11:39:22.342407",
     "exception": false,
     "start_time": "2021-08-16T11:39:22.292048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33bb980a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T11:39:22.453254Z",
     "iopub.status.busy": "2021-08-16T11:39:22.452553Z",
     "iopub.status.idle": "2021-08-16T11:39:22.456006Z",
     "shell.execute_reply": "2021-08-16T11:39:22.455578Z",
     "shell.execute_reply.started": "2021-08-16T08:54:07.259247Z"
    },
    "id": "awnxUrddbvRC",
    "papermill": {
     "duration": 0.06346,
     "end_time": "2021-08-16T11:39:22.456113",
     "exception": false,
     "start_time": "2021-08-16T11:39:22.392653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, en_vocab, hi_vocab, device, max_length=50):\n",
    "\n",
    "  # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "  if type(sentence) == str:\n",
    "    tokens = [tok.text.lower() for tok in spacy_eng.tokenizer(sentence)]\n",
    "  else:\n",
    "    tokens = [token.lower() for token in sentence]\n",
    "\n",
    "\n",
    "  # Add <SOS> and <EOS> in beginning and end respectively\n",
    "  tokens.insert(0, '<sos>')\n",
    "  tokens.append('<eos>')\n",
    "\n",
    "  # Go through each english token and convert to an index\n",
    "  text_to_indices = [en_vocab.stoi[token] if token in en_vocab.stoi else en_vocab.stoi['<unk>'] for token in tokens]\n",
    "\n",
    "  # Convert to Tensor\n",
    "  sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)   # (source_len x batch_size) => (tokens_length, 1)\n",
    "\n",
    "  # Build encoder hidden, cell state\n",
    "  with torch.no_grad():\n",
    "      encoder_states, hidden, cell = model.encoder(sentence_tensor)\n",
    "\n",
    "  outputs = [hi_vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "  for _ in range(max_length):\n",
    "      previous_word = torch.LongTensor([outputs[-1]]).to(device) # shape: (1)\n",
    "\n",
    "      with torch.no_grad():\n",
    "          output, hidden, cell = model.decoder(previous_word, encoder_states, hidden, cell) # output  shape: (batch_size, target_vocab_size) => (1, hindi_vocab_size)\n",
    "          best_guess = output.argmax(1).item()\n",
    "\n",
    "      outputs.append(best_guess)\n",
    "\n",
    "      # Model predicts it's the end of the sentence\n",
    "      if output.argmax(1).item() == hi_vocab.stoi[\"<eos>\"]:\n",
    "          break\n",
    "\n",
    "  translated_sentence = [hi_vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "  # remove start token\n",
    "  return translated_sentence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f2e43a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T11:39:22.560554Z",
     "iopub.status.busy": "2021-08-16T11:39:22.560019Z",
     "iopub.status.idle": "2021-08-16T11:39:22.573607Z",
     "shell.execute_reply": "2021-08-16T11:39:22.573220Z",
     "shell.execute_reply.started": "2021-08-16T08:54:07.822530Z"
    },
    "id": "W1PZPDrB99yI",
    "outputId": "dad767de-cbd1-4863-fa24-15a6aacc5696",
    "papermill": {
     "duration": 0.067459,
     "end_time": "2021-08-16T11:39:22.573747",
     "exception": false,
     "start_time": "2021-08-16T11:39:22.506288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence: So there is some sort of justice\n",
      "Translated sentence: तो वहाँ न्याय है <eos>\n"
     ]
    }
   ],
   "source": [
    "sentence1 = 'So there is some sort of justice'\n",
    "pred1 = translate_sentence(model, sentence1, en_vocab, hi_vocab, device, max_length=50)\n",
    "pred1 = ' '.join(pred1)\n",
    "print(f'Source Sentence: {sentence1}')\n",
    "print(f'Translated sentence: {pred1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a354870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T11:39:22.678941Z",
     "iopub.status.busy": "2021-08-16T11:39:22.678395Z",
     "iopub.status.idle": "2021-08-16T11:39:22.696895Z",
     "shell.execute_reply": "2021-08-16T11:39:22.696427Z",
     "shell.execute_reply.started": "2021-08-16T08:54:18.730778Z"
    },
    "id": "qvqb1XEiuMd6",
    "outputId": "6c8d21f4-3e84-45cf-8115-717ced158c86",
    "papermill": {
     "duration": 0.072682,
     "end_time": "2021-08-16T11:39:22.697004",
     "exception": false,
     "start_time": "2021-08-16T11:39:22.624322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence: And who are we to say, even, that they are wrong\n",
      "Translated sentence: और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं <eos>\n"
     ]
    }
   ],
   "source": [
    "sentence2 = 'And who are we to say, even, that they are wrong'\n",
    "pred2 = translate_sentence(model, sentence2, en_vocab, hi_vocab, device, max_length=50)\n",
    "pred2 = ' '.join(pred2)\n",
    "print(f'Source Sentence: {sentence2}')\n",
    "print(f'Translated sentence: {pred2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f98bdb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T11:39:22.808992Z",
     "iopub.status.busy": "2021-08-16T11:39:22.808278Z",
     "iopub.status.idle": "2021-08-16T11:40:37.192487Z",
     "shell.execute_reply": "2021-08-16T11:40:37.192921Z",
     "shell.execute_reply.started": "2021-08-16T08:54:27.754768Z"
    },
    "id": "qyE01W1WAJ64",
    "outputId": "55a42644-0cd3-4056-b49d-e3219feb6b9d",
    "papermill": {
     "duration": 74.445362,
     "end_time": "2021-08-16T11:40:37.193324",
     "exception": false,
     "start_time": "2021-08-16T11:39:22.747962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bleu Score on test dataset: 0.427711\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "running_bleu_score = []\n",
    "for idx, (en, hi) in enumerate(test_loader):\n",
    "  # shape of en: (eng_source_len, batch_size)\n",
    "  # shape of hi: (hindi_source_len, batch_size)\n",
    "\n",
    "  for batch_id in range(en.shape[1]):\n",
    "    e = en[:, 0]\n",
    "    h = hi[:, 0]\n",
    "\n",
    "    en_sen = []\n",
    "    hi_sen = []\n",
    "    for i in range(e.shape[0]):\n",
    "      if e[i].item() > 3:\n",
    "        en_sen.append(en_vocab.itos[e[i].item()])\n",
    "\n",
    "    for i in range(h.shape[0]):\n",
    "      if h[i].item() > 3:\n",
    "        hi_sen.append(hi_vocab.itos[h[i].item()])\n",
    "      \n",
    "    en_sentence = ' '.join(en_sen)\n",
    "    true_hi_sentence = ' '.join(hi_sen)\n",
    "    pred_hi_sentence = translate_sentence(model, en_sentence, en_vocab, hi_vocab, device, max_length=50)\n",
    "\n",
    "    if pred_hi_sentence[-1] == '<eos>':\n",
    "      pred_hi_sentence = pred_hi_sentence[:-1]\n",
    "    pred_hi_sentence = ' '.join(pred_hi_sentence)\n",
    "\n",
    "    # print(true_hi_sentence, ' | ',  pred_hi_sentence)\n",
    "\n",
    "    bleu_score_ = bleu.sentence_bleu([true_hi_sentence.split()], pred_hi_sentence.split())\n",
    "\n",
    "    # print(true_hi_sentence, ' | ',  pred_hi_sentence)\n",
    "    # print(bleu_score_)\n",
    "\n",
    "    running_bleu_score.append(bleu_score_)\n",
    "\n",
    "mean_bleu_score = np.array(running_bleu_score).mean()\n",
    "print(f'Mean Bleu Score on test dataset: {mean_bleu_score:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e039bf",
   "metadata": {
    "id": "VobAoAoFp4py",
    "papermill": {
     "duration": 0.051581,
     "end_time": "2021-08-16T11:40:37.300631",
     "exception": false,
     "start_time": "2021-08-16T11:40:37.249050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9672.16203,
   "end_time": "2021-08-16T11:40:39.788068",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-16T08:59:27.626038",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
